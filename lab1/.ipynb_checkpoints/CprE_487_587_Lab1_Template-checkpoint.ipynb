{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 21:05:03.498908: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-07 21:05:04.058087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-07 21:05:04.333402: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-07 21:05:04.335382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-07 21:05:04.768775: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-07 21:05:07.147007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-07 21:05:12.924512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 21:05:12.949481: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 21:05:12.949616: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 21:05:12.951708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 21:05:12.951825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 21:05:12.951887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Python Version: 3.9.21 (main, Feb 10 2025, 00:00:00) \n",
      "[GCC 11.5.0 20240719 (Red Hat 11.5.0-5)]\n",
      "Using Tensorflow Version: 2.16.2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cudaSetDevice() on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning on CPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing GPU at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mgpu_device_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m available)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/cpre_5870/lab1/Lab1/lab1_venv/lib64/python3.9/site-packages/tensorflow/python/framework/test_util.py:186\u001b[0m, in \u001b[0;36mgpu_device_name\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.gpu_device_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgpu_device_name\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the name of a GPU device if available or a empty string.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  This method should only be used in tests written with `tf.test.TestCase`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdevice_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_local_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    188\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mas_str(x\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/cpre_5870/lab1/Lab1/lab1_venv/lib64/python3.9/site-packages/tensorflow/python/client/device_lib.py:41\u001b[0m, in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   serialized_config \u001b[38;5;241m=\u001b[39m session_config\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m---> 41\u001b[0m     _convert(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_pywrap_device_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cudaSetDevice() on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "import pathlib, os, sys, operator, re, datetime\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "from tiny_imagenet import TinyImagenetDataset\n",
    "\n",
    "# Enable or disable GPU\n",
    "# To fully disable it, we need to hide all GPU devices from Tensorflow\n",
    "# Make sure GPU is disabled for this inference part of the lab\n",
    "ENABLE_GPU = TRUE\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "if not ENABLE_GPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Print Python and TF version, and where we are running\n",
    "print(f'Running on Python Version: {sys.version}')\n",
    "print(f'Using Tensorflow Version: {tf. __version__}')\n",
    "if not tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "    print('Running on CPU')\n",
    "else:\n",
    "    print(f'Using GPU at: {tf.test.gpu_device_name()} (of {len(tf.config.experimental.list_physical_devices(\"GPU\"))} available)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports our dataset.\n",
    "\n",
    "# Original Source: https://github.com/ksachdeva/tiny-imagenet-tfds\n",
    "# Class Version Source: https://github.com/duweisu/tiny-imagenet-tfds\n",
    "# Setup our dataset\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "tiny_imagenet_builder = TinyImagenetDataset()\n",
    "\n",
    "# this call (download_and_prepare) will trigger the download of the dataset\n",
    "# and preparation (conversion to tfrecords)\n",
    "#\n",
    "# This will be done only once and on next usage tfds will\n",
    "# use the cached version on your host.\n",
    "tiny_imagenet_builder.download_and_prepare(download_dir=\"~/tensorflow-datasets/downloads\")\n",
    "\n",
    "# class_names = tiny_imagenet_builder.info.features['label'].names\n",
    "ds = tiny_imagenet_builder.as_dataset()\n",
    "ds_train, ds_val = ds[\"train\"], ds[\"validation\"]\n",
    "assert(isinstance(ds_train, tf.data.Dataset))\n",
    "assert(isinstance(ds_val, tf.data.Dataset))\n",
    "\n",
    "# Training Dataset\n",
    "ds_train = ds_train.shuffle(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Validation Dataset\n",
    "ds_val = ds_val.shuffle(1024).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Dataset metadata\n",
    "ds_info = tiny_imagenet_builder.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to read the \"human readable\" labels so we can translate with the numeric values\n",
    "# Read the labels file (words.txt)\n",
    "with open(os.path.abspath('wnids.txt'), 'r') as f:\n",
    "    wnids = [x.strip() for x in f]\n",
    "\n",
    "# Map wnids to integer labels\n",
    "wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n",
    "label_to_wnid = {v: k for k, v in wnid_to_label.items()}\n",
    "\n",
    "# Use words.txt to get names for each class\n",
    "with open(os.path.abspath('words.txt'), 'r') as f:\n",
    "    wnid_to_words = dict(line.split('\\t') for line in f)\n",
    "    for wnid, words in wnid_to_words.items():\n",
    "        wnid_to_words[wnid] = [w.strip() for w in words.split(',')]\n",
    "        \n",
    "class_names = [str(wnid_to_words[wnid]) for wnid in wnids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the label name\n",
    "def img_class(img_data, idx=None):\n",
    "    image, label, id, label_name = img_data[\"image\"], img_data[\"label\"], img_data[\"id\"], img_data[\"metadata\"]['label_name']\n",
    "    # Handle batches of images correctly\n",
    "    if idx != None:\n",
    "        image, label, id, label_name = img_data[\"image\"][idx], img_data[\"label\"][idx], img_data[\"id\"][idx], img_data[\"metadata\"]['label_name'][idx]\n",
    "    \n",
    "    return f\"{label_name} (class index: {label} - id: {id})\"\n",
    "\n",
    "\n",
    "# Helper function to show basic info about an image\n",
    "def img_info(img, idx=None, display=True, title_apend=\"\"):\n",
    "    image = img['image']\n",
    "\n",
    "    # Print the class\n",
    "    class_str = img_class(img, idx)\n",
    "    print(f\"Label: {class_str}\")\n",
    "    \n",
    "    # Display the image\n",
    "    if display:\n",
    "        plt.figure()\n",
    "        plt.title(title_apend + class_str)\n",
    "        # Handle batches correctly\n",
    "        if image.shape.ndims > 3:\n",
    "            plt.imshow(image.numpy().reshape(64, 64, 3))\n",
    "        else:\n",
    "            plt.imshow(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the dataset types and info\n",
    "print(\"--- Train & Validation dataset info ---\")\n",
    "print(f\"Train: {ds_train}\")\n",
    "print(f\"Validation: {ds_val}\")\n",
    "# print(f\"Dataset Info: {ds_info}\") # Uncomment to print Dataset info\n",
    "\n",
    "print(\"\\n--- Show an example image ---\")\n",
    "for example in ds_val.take(1):\n",
    "    img_info(example)\n",
    "\n",
    "print(\"\\n Show some other examples\")\n",
    "tfds.show_examples(ds_val, ds_info, rows=3, cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print and visualize three inputs from the validation set\n",
    "#     : Print the stroage data type\n",
    "#     : Print and note the dimensions of each image\n",
    "#     : Print the memory required to store each image\n",
    "\n",
    "# Sample Images\n",
    "sample_imgs = []\n",
    "for index, img_data in enumerate(ds_val.take(3)):\n",
    "    sample_imgs.append(img_data)\n",
    "    image, label, id, label_name = img_data[\"image\"], img_data[\"label\"], img_data[\"id\"], img_data[\"metadata\"]['label_name']\n",
    "\n",
    "    print(f'\\n--- Image {index} ---')\n",
    "    # TODO: Your Code Here\n",
    "    img_info(img_data)\n",
    "    print(f\"Data Type - {image.dtype}\")\n",
    "    print(f\"Dimensions - {image.shape}\")\n",
    "    print(\"uint8 = 1 byte\\n64 x 64 x 3 * 1 byte = 12228 bytes\")\n",
    "    # See example usage: https://github.com/duweisu/tiny-imagenet-tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export each of the three inputs to a binary file which will be used to load the images into C++ later\n",
    "# NOTE: First flatten the array (ex: 4D --> 1D). So 64*64*3 = 12288 element 1D array\n",
    "\n",
    "# Make a directory for our image data\n",
    "img_dir = os.path.abspath('img_data')\n",
    "pathlib.Path(img_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# Create a metadata file\n",
    "metadata_file = open(os.path.join(img_dir, f'metadata.txt'), 'w')\n",
    "metadata_file.write(f'Number\\t\\tDims\\t\\tClass Data\\n')\n",
    "\n",
    "# Export each image\n",
    "for index, img_data in enumerate(sample_imgs):    \n",
    "    img_file = open(os.path.join(img_dir, f'image_{index}.bin'), 'wb')\n",
    "    \n",
    "    # TODO: Your Code Here\n",
    "    arr = img_data[\"image\"].numpy()\n",
    "    label = img_data[\"label\"].numpy()\n",
    "    flat_arr = arr.flatten()\n",
    "    img_file.write(flat_arr.tobytes())\n",
    "    img_file.close()\n",
    "    metadata_file.write(f\"{index}\\t\\t{image.shape}\\t\\t{label}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the model\n",
    "# Now we will load the H5 model! Please make sure the h5 model file is present in the below directory.\n",
    "# You can download this from the Canvas Page and place it in the same directory as this notebook.\n",
    "\n",
    "# model_path = os.path.abspath(\"\"/home/<NETID>/path/to/your/lab1/CNN_TinyImageNet.h5)\" # Uncomment this to use a non-relative path\n",
    "model_path = os.path.abspath(\"CNN_TinyImageNet.h5\")\n",
    "\n",
    "# TODO: Your Code Here\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running infrence on our model\n",
    "# We can run an infrence of our model by doing the following (we are doing batches of 1 here)\n",
    "for example in ds_train.batch(1).take(1):\n",
    "    img_info(example)\n",
    "    # Make a prediction\n",
    "    pred = model.predict(tf.cast(example[\"image\"], tf.float32)/255.0)\n",
    "    # print(f'Raw 200 Class Weighted Prediction:\\n{pred}') # Uncomment to see the raw prediction\n",
    "    \n",
    "    # What is out best guess?\n",
    "    best_guess = tf.math.argmax(pred, axis=1).numpy() # Our output is 200 weighted value, we want the most likely\n",
    "    print(f'Best Guess [class index]: {class_names[best_guess[0]]} [{best_guess[0]}]')\n",
    "    print(f'Best Guess Confidence (percent / 1.0): {pred[0][best_guess]}')\n",
    "\n",
    "    # What are our top 15 guesses?\n",
    "    top_15 = tf.math.top_k(pred, k=15)\n",
    "    print(f'Top 15 Guesses (class index): {[f\"{class_names[idx]} [{idx}]\" for idx in top_15.indices[0]]}')\n",
    "    print(f'Top 15 Guesses Confidence (percent / 1.0): {top_15.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run infrence for our previous 3 sample images\n",
    "\n",
    "# TODO: Your Code Here\n",
    "\n",
    "# for index, img_data in enumerate(sample_imgs):\n",
    "    \n",
    "#     pred = model.predict(tf.cast(img_data[\"image\"], tf.float32)/255.0)\n",
    "#     sample_predictions.append(pred)\n",
    "#     best_guess = tf.math.argmax(sample_predictions[index], axis=1).numpy()\n",
    "#     label = sample_predictions[index][\"label\"].numpy()\n",
    "#     print(f\"{best_guess}\\t\\t{pred[0][best_guess]}\\t\\t\")\n",
    "\n",
    "# Stack all 3 sample images into a stack for the prediction model (3, 64, 64, 3)\n",
    "imgs = tf.stack([tf.cast(d[\"image\"], tf.float32) / 255.0 for d in sample_imgs], axis = 0)\n",
    "\n",
    "preds = model.predict(imgs)\n",
    "\n",
    "print(f\"Best guess\\t\\tAssoc. Conf.\\t\\tActual Class\\n\")\n",
    "for i, pred in enumerate(preds):\n",
    "    best_guess = np.argmax(pred)\n",
    "    confidence = pred[best_guess]\n",
    "    label = sample_imgs[i][\"label\"].numpy()\n",
    "\n",
    "    print(f\"{best_guess}\\t\\t{confidence}\\t\\t{label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Calculate the Top-1, Top-5, and Top-10 Accuracy of the validation dataset\n",
    "# total = acc_top1 = acc_top5 = acc_top10 = 0\n",
    "# total = ds_val.cardinality().numpy()\n",
    "# # TODO: Your Code Here\n",
    "# for images in ds_val.batch(32):\n",
    "#     # Predict the classes for each image, in a batch of 32 images at a time\n",
    "#     preds = model.predict(tf.cast(images[\"image\"], tf.float32)/255.0, verbose = 0)\n",
    "#     labels = images[\"label\"].numpy()\n",
    "\n",
    "#     for i, pred in enumerate(preds):\n",
    "#         top_1 = np.argmax(pred)\n",
    "#         if top_1 == labels[i]:\n",
    "#             acc_top1 += 1\n",
    "\n",
    "#         # top_5 = tf.math.top_k(pred, n=5)\n",
    "#         # for j in range(5):\n",
    "#         #     if top_5[j] == labels[i]:\n",
    "#         #         acc_top5 += 1\n",
    "#         #         break\n",
    "\n",
    "#         # top_10 = tf.math.top_k(pred, n=10)\n",
    "#         # for j in range(10):\n",
    "#         #     if top_10[j] == labels[i]:\n",
    "#         #         acc_top10 += 1\n",
    "#         #         break\n",
    "\n",
    "#         top_5 = tf.math.top_k(pred, k=5).indices.numpy()\n",
    "#         if labels[i] in top_5:\n",
    "#             acc_top5 += 1\n",
    "\n",
    "#         top_10 = tf.math.top_k(pred, k=10).indices.numpy()\n",
    "#         if labels[i] in top_10:\n",
    "#             acc_top10 += 1\n",
    "\n",
    "# print(f\"Top 1 Accuracy: {acc_top1/total}\\n\")\n",
    "# print(f\"Top 5 Accuracy: {acc_top5/total}\\n\")\n",
    "# print(f\"Top 10 Accuracy: {acc_top10/total}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Print all of the possible classes of the dataset\n",
    "\n",
    "# # TODO: Your Code Here\n",
    "# train_labels = set()\n",
    "# for batch in ds_train.batch(32):\n",
    "#     train_labels.update(batch[\"label\"].numpy().tolist())\n",
    "\n",
    "# val_labels = set()\n",
    "# for batch in ds_train.batch(32):\n",
    "#     val_labels.update(batch[\"label\"].numpy().tolist())\n",
    "\n",
    "# print(\"Training classes:\", len(train_labels))\n",
    "# print(\"Validation classes:\", len(val_labels))\n",
    "\n",
    "# for i in range(200):\n",
    "#     print({class_names[i],})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the model in Netron (https://netron.app/) and include an image here.\n",
    "# tf.keras.utils.plot_model(model, \"model.png\", show_shapes=True, show_dtype=True, expand_nested=True) # Uncomment this to generate a simple visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view the layer weights. Here we consider them as images of feature filters applied to intermediate feature map images.\n",
    "# TODO: Visualize the 2 convolutional layers filter sets (weights) (one at the beginning and one at the end)\n",
    "\n",
    "# TODO: Your Code Here\n",
    "conv_layers = [l for l in model.layers if isinstance(l, tf.keras.layers.Conv2D)]\n",
    "first_conv = conv_layers[0]\n",
    "last_conv = conv_layers[-2]\n",
    "\n",
    "def describe_layer(layer):\n",
    "    W, b = layer.get_weights()\n",
    "    n_params = W.size + b.size\n",
    "    mem_bytes = W.nbytes + b.nbytes\n",
    "    print(f\"\\nLayer: {layer.name} ({layer.__class__.__name__})\")\n",
    "    print(f\"Weights shape: {W.shape}, Bias shape: {b.shape}\")\n",
    "    print(f\"dtype: {W.dtype}\")\n",
    "    print(f\"Params: {n_params:,}\")\n",
    "    print(f\"Memory: {mem_bytes} bytes\")\n",
    "    return W,b\n",
    "\n",
    "W1, b1 = describe_layer(first_conv)\n",
    "W2, b2 = describe_layer(last_conv)\n",
    "\n",
    "def normalize(x):\n",
    "    x = x - x.min()\n",
    "    m = x.min()\n",
    "    return x / (m if m != 0 else 1.0)\n",
    "\n",
    "num_show1 = min(16, W1.shape[-1])\n",
    "cols = 8\n",
    "rows = int(num_show1 / cols)\n",
    "plt.figure()\n",
    "for i in range(num_show1):\n",
    "    f = W1[:, :, :, i]\n",
    "    f_img = normalize(f)\n",
    "    ax = plt.subplot(rows, cols, i+1)\n",
    "    ax.imshow(f_img)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "plt.suptitle(f\"{first_conv.name} first {num_show1} filters\")\n",
    "plt.show()\n",
    "\n",
    "num_show2 = min(16, W2.shape[-1])\n",
    "rows = int(num_show2 / cols)\n",
    "plt.figure()\n",
    "for i in range(num_show2):\n",
    "    k = W2[:, :, :, i]\n",
    "    energy = np.sqrt((k**2).sum(axis=2))\n",
    "    e_img = normalize(energy)\n",
    "    ax = plt.subplot(rows, cols, i+1)\n",
    "    ax.imshow(e_img)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "plt.suptitle(f\"{last_conv.name} first {num_show2} filters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view the layer outputs as well. Here we consider them as images of the spatial location of features.\n",
    "# TODO: Visualize the 2 convolutional layers outputs (intermediate feature maps) (one at the beginning and one at the end)\n",
    "\n",
    "# TODO: Your Code Here\n",
    "\n",
    "example = next(iter(ds_val.batch(1)))\n",
    "x = tf.cast(example[\"image\"], tf.float32) /  255.0\n",
    "\n",
    "acts = {}\n",
    "t = x\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        t = layer(t, training = False)\n",
    "    except TypeError:\n",
    "        t = layer(t)\n",
    "    if layer is first_conv:\n",
    "        acts[\"first\"] = t.numpy()\n",
    "    if layer is last_conv:\n",
    "        acts[\"last\"] = t.numpy()\n",
    "\n",
    "feat_first = acts[\"first\"]\n",
    "feat_last = acts[\"last\"]\n",
    "\n",
    "def show_feature_maps(F, layer_name, channels=(0, -1), cmap = \"magma\"):\n",
    "    F0 = np.asarray(F)[0]\n",
    "    H, W, C = F0.shape\n",
    "    print(f\"Layer name: {layer_name} \")\n",
    "    print(f\"feature map shape = {(1, H, W, C)}\")\n",
    "    print(f\"dtype{F.dtype}\")\n",
    "    print(f\"Data size: {F.nbytes}\")\n",
    "    plt.figure(figsize=(4*len(channels), 4))\n",
    "    for i, ch in enumerate(channels):\n",
    "        fm = F0[..., ch]\n",
    "        fm = (fm - fm.min()) / (fm.max() - fm.min() + 1e-8)\n",
    "        ax = plt.subplot(1, len(channels), i+1)\n",
    "        ax.imshow(fm, cmap=cmap)\n",
    "        ax.set_title(f\"{layer_name} channel {ch}\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_feature_maps(feat_first, first_conv.name)\n",
    "show_feature_maps(feat_last, last_conv.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export the filters/weights se we can use them later\n",
    "# Make a directory for our image data\n",
    "model_dir = os.path.abspath('model_data')\n",
    "pathlib.Path(model_dir).mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Export each image\n",
    "conv_index = dense_index = 1 # layer index starts from one\n",
    "for layer_idx, layer in enumerate(model.layers):\n",
    "    if re.match(r'(conv|dense)', layer.name):\n",
    "        weight_file_name = os.path.join(model_dir, f'{layer.name}_weights.bin')\n",
    "        bias_file_name = os.path.join(model_dir, f'{layer.name}_bias.bin')\n",
    "    else: continue\n",
    "\n",
    "    assert layer.weights[0].name.endswith('kernel')\n",
    "    assert layer.weights[1].name.endswith('bias')\n",
    "        \n",
    "    # TODO: Your Code Here\n",
    "    W, b = layer.get_weights()\n",
    "\n",
    "    with open(weight_file_name, \"wb\") as wf:\n",
    "        wf.write(W.tobytes())\n",
    "\n",
    "    with open(bias_file_name, \"wb\") as bf:\n",
    "        bf.write(b.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export the intermediate layer outputs for each of the input for all of the layers\n",
    "img_dir = os.path.abspath('img_data')\n",
    "pathlib.Path(img_dir).mkdir(exist_ok=True)\n",
    "\n",
    "for img_idx, img in enumerate(sample_imgs):\n",
    "    file_dir = os.path.join(img_dir, f'test_input_{img_idx}')\n",
    "    pathlib.Path(file_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # TODO: Your Code Here\n",
    "    x = tf.cast(img[\"image\"], tf.float32)[None, ...] / 255.0\n",
    "    t = x\n",
    "    for layer in model.layers:\n",
    "        try: \n",
    "            t = layer(t, training = False)\n",
    "        except TypeError:\n",
    "            t = layer(t)\n",
    "        \n",
    "        arr = t.numpy()\n",
    "        out_path = os.path.join(file_dir, f\"{layer.name}.bin\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(arr.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(False)\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "# Setup for profiling\n",
    "opts = tf.profiler.experimental.ProfilerOptions(\n",
    "    host_tracer_level=2, python_tracer_level=0, device_tracer_level=1\n",
    ")\n",
    "\n",
    "log_dir = os.path.abspath(os.path.join('log_data'))\n",
    "log_dir_run = os.path.abspath(os.path.join(log_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "pathlib.Path(log_dir_run).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "try:\n",
    "    tf.profiler.experimental.stop()\n",
    "except:\n",
    "    test = 2\n",
    "finally:\n",
    "    test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample Profiling - Inference for a single image:\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# tf.profiler.experimental.start(log_dir_run)\n",
    "\n",
    "latency = []\n",
    "\n",
    "@tf.function(jit_compile=False)\n",
    "def run_infer(x):\n",
    "    return model(x, training = False)\n",
    "\n",
    "_ = run_infer(tf.zeros((1,64,64,3), tf.float32))\n",
    "\n",
    "# Perform the inference profiling:\n",
    "for i, image in enumerate(sample_imgs):\n",
    "    # Starts Profile logging\n",
    "    sub_dir = os.path.join(log_dir_run, f'img_{i}')\n",
    "    x = tf.cast(image[\"image\"], tf.float32)\n",
    "    x = tf.expand_dims(x, axis = 0) / 255.0\n",
    "    tf.profiler.experimental.start(sub_dir, options=opts)\n",
    "    try:\n",
    "        tf.profiler.experimental.Trace(\"single_inference\", step_num = 0, _r = 1)\n",
    "        t0 = time.perf_counter()\n",
    "        pred = run_infer(x)\n",
    "        _ = pred.numpy()\n",
    "        t1 = time.perf_counter()\n",
    "        latency.append((t1-t0) * 1e3)\n",
    "    finally:\n",
    "        tf.profiler.experimental.stop()\n",
    "        print(f'Latency for Image {i}: {latency[i]}')\n",
    "    \n",
    "    file_writer = tf.summary.create_file_writer(sub_dir)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar(\"latency_ms\", latency[i], step=0)\n",
    "    file_writer.flush()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile. \n",
    "# *** Please note just execute this command once in a session and \n",
    "# then logs for subsequent runs would be auto detected in tensorboard- url: http://localhost:6006/\n",
    "print(log_dir_run)\n",
    "%tensorboard --logdir={log_dir_run} --port=6006\n",
    "\n",
    "# You can view the tensorboard in the browser url: http://localhost:6006/\n",
    "\n",
    "# Useful command line to have if tensorboard is misbehaving: kill $(ps -e | grep 'tensorboard' | awk '{print $1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample Profiling - Online Inference:\n",
    "\n",
    "# Vary this from 10, 100, 1000 to simulate multiple online inference\n",
    "loop_index = [10, 100, 1000]\n",
    "\n",
    "for idx in loop_index:\n",
    "    sub_dir = os.path.join(log_dir_run, f'loop_{idx}')\n",
    "    tf.profiler.experimental.start(sub_dir, options=opts)\n",
    "    for img in ds_val.batch(1).take(idx):\n",
    "        x = tf.cast(img['image'], tf.float32)/255.0\n",
    "        tf.profiler.experimental.Trace(\"Multiple Online Inference Profiling\", step_num = 0, _r = 1)\n",
    "        pred = run_infer(x)\n",
    "        _ = pred.numpy()\n",
    "    tf.profiler.experimental.stop()\n",
    "    print(f'latency test for set {idx} done')\n",
    "    file_writer = tf.summary.create_file_writer(sub_dir)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar(\"latency_ms\", latency[i], step=0)\n",
    "    file_writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample Profiling - Batch Inference:\n",
    "\n",
    "# We would only perform batch inference for a subset of validation set i.e. 1000 images \n",
    "# using different batch sizes of 20, 40, 100, 200 \n",
    "\n",
    "# Decides the size of the batch. Try: 20, 40, 100, 200\n",
    "batch_size = [20, 40, 100, 200]\n",
    "\n",
    "for batch in batch_size:\n",
    "    sub_dir = os.path.join(log_dir_run, f'batch_{batch}')\n",
    "    tf.profiler.experimental.start(sub_dir, options=opts)\n",
    "    for imgs in ds_val.take(1000).batch(batch):\n",
    "        imgs_stzd = tf.cast(imgs['image'], tf.float32)/255.0\n",
    "        tf.profiler.experimental.Trace(\"Batch Inference Profiling\", step_num = 0, _r = 1)\n",
    "        pred = run_infer(imgs_stzd)\n",
    "        _ = pred.numpy()\n",
    "    tf.profiler.experimental.stop()\n",
    "    print(f'latency test for batch {batch} done')\n",
    "\n",
    "    file_writer = tf.summary.create_file_writer(sub_dir)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar(\"latency_ms\", latency[i], step=0)\n",
    "    file_writer.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for model training\n",
    "from tensorflow.keras import Model, datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D,Convolution2D, Activation, Dropout \n",
    "\n",
    "train_dir = os.path.abspath(os.path.join('train_data', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "pathlib.Path(train_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Using early stopping to monitor validation accuracy\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=train_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CNN model\n",
    "train_model = Sequential()\n",
    "\n",
    "# conv1\n",
    "train_model.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3), activation='relu'))\n",
    "train_model.add(Conv2D(32, (5,5),activation='relu'))\n",
    "train_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "train_model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "train_model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "train_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "train_model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "train_model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "train_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "train_model.add(Flatten())\n",
    "\n",
    "# fc1\n",
    "train_model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# fc2\n",
    "train_model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "train_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# TODO: Consider looking at different optimizers and learning rate settings\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Attempt to train your own model with different batch sizes\n",
    "# TODO: See how long this takes without a GPU on your VDI or 2050 Coover machines\n",
    "# TODO: THEN log in to your GPU VM, set ENABLE_GPU = False in the very first cell, and re-run all above cells\n",
    "# TODO: Make sure you have exported the LD_LIBRARY_PATH as the lab manual indicates\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "def to_categorical(image, label):\n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), 200)\n",
    "    return tf.cast(image, tf.float32), tf.cast(label, tf.int64)\n",
    "\n",
    "ds_re = tiny_imagenet_builder.as_dataset(as_supervised=True)\n",
    "ds_retrain, ds_reval = ds_re[\"train\"], ds_re[\"validation\"]\n",
    "\n",
    "ds_retrain = ds_retrain.cache().shuffle(1024)\n",
    "ds_reval = ds_reval.cache().shuffle(1024)\n",
    "\n",
    "ds_retrain = ds_retrain.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_reval = ds_reval.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "ds_retrain = ds_retrain.map(to_categorical, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_reval = ds_reval.map(to_categorical, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "epoch_size = 20\n",
    "\n",
    "init_weights = train_model.get_weights()\n",
    "\n",
    "for batch_size in [32, 64, 128]:\n",
    "    # Setup our batched datasets\n",
    "    ds_retrain_batches = ds_retrain.batch(batch_size)\n",
    "    ds_reval_batches = ds_retrain.batch(batch_size)\n",
    "\n",
    "    train_model.fit(\n",
    "        ds_retrain_batches, \n",
    "        epochs = epoch_size, \n",
    "        validation_data = ds_reval_batches,\n",
    "        callbacks = callbacks\n",
    "    )\n",
    "    \n",
    "    train_model.save(os.path.join(train_dir, f'CNN_Train_Batch_Size_{batch_size}.h5'))\n",
    "\n",
    "    total = ds_reval.cardinality().numpy()\n",
    "\n",
    "    for images in ds_reval.batch(batch_size):\n",
    "        preds = train_model.predict(tf.cast(images['image'], tf.float32)/255.0, verbose = 0)\n",
    "        labels = images['label'].numpy()\n",
    "\n",
    "        for i, pred in enumerate(preds):\n",
    "            top_1 = np.argmax(pred)\n",
    "            if top_1 == labels[i]:\n",
    "                acc_top1 += 1\n",
    "            \n",
    "            top_5 = tf.math.top_k(pred, k=5).indices.numpy()\n",
    "            if labels[i] in top_5:\n",
    "                acc_top5 += 1\n",
    "\n",
    "        print(f\"Top 1 Accuracy: {acc_top1/total}\\n\")\n",
    "        print(f\"Top 5 Accuracy: {acc_top5/total}\\n\")\n",
    "\n",
    "    train_model.set_weights(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model with 3 different numbers of epochs\n",
    "batch_size = 32\n",
    "\n",
    "# Setup your datasets\n",
    "ds_retrain_batches = ds_retrain.batch(batch_size)\n",
    "ds_reval_batches = ds_reval.batch(batch_size)\n",
    "\n",
    "for epoch_size in [3, 10, 100]:\n",
    "    train_model.fit(\n",
    "        ds_retrain_batches,\n",
    "        epochs = epoch_size,\n",
    "        validation_data = ds_reval_batches,\n",
    "        callbacks = callbacks\n",
    "    )\n",
    "\n",
    "    # Save the cnn model\n",
    "    train_model.save(os.path.join(train_dir, f'CNN_Train_Epoch_Size_{epoch_size}.h5'))\n",
    "\n",
    "    #Get top 1 and top 5 percentages\n",
    "    for images in ds_reval.batch(batch_size):\n",
    "        preds = train_model.predict(tf.cast(images['image'], tf.float32)/255.0, verbose = 0)\n",
    "        labels = images['label'].numpy()\n",
    "\n",
    "        for i, pred in enumerate(preds):\n",
    "            top_1 = np.argmax(pred)\n",
    "            if top_1 == labels[i]:\n",
    "                acc_top1 += 1\n",
    "            \n",
    "            top_5 = tf.math.top_k(pred, k=5).indices.numpy()\n",
    "            if labels[i] in top_5:\n",
    "                acc_top5 += 1\n",
    "\n",
    "        print(f\"Top 1 Accuracy: {acc_top1/total}\\n\")\n",
    "        print(f\"Top 5 Accuracy: {acc_top5/total}\\n\")\n",
    "\n",
    "    train_model.set_weights(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above and Beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark our dataset to make sure loading our data isn't a bottleneck ... and because we can\n",
    "# (This can be skipped since it can take a bit and is't all that important)\n",
    "\n",
    "# tfds.benchmark(ds_train.batch(32), batch_size=32, num_iter=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore new models to find a higher-accuracy model. Does the new model require more or less time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
